{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell, some libraries were imported\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import pylab\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from pynq.overlays.base import BaseOverlay\n",
    "base = BaseOverlay(\"base.bit\")\n",
    "\n",
    "from pynq.overlays.base import BaseOverlay\n",
    "from pynq.lib.video import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ServiceAccountCredentials' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c79f3941e7ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# use creds to create a client to interact with the Google Drive API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'https://spreadsheets.google.com/feeds'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mServiceAccountCredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_json_keyfile_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'client_secret.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgspread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ServiceAccountCredentials' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# use creds to create a client to interact with the Google Drive API\n",
    "scope = ['https://spreadsheets.google.com/feeds']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('client_secret.json', scope)\n",
    "client = gspread.authorize(creds)\n",
    " \n",
    "# Find a workbook by name and open the first sheet\n",
    "# Make sure you use the right name here.\n",
    "sheet = client.open(\"Xilinx_Hackathon_2017\").sheet1\n",
    "\n",
    "\n",
    "###### ORB\n",
    "# imports for ORB\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Initiate ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# create BFMatcher object\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "import string\n",
    "import re\n",
    "####################################\n",
    "######   Configurable items:  ######\n",
    "####################################\n",
    "# arbitary number. Fine tune once you get here\n",
    "thres_hold = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture(destination, image_number):\n",
    "    orig_img_path = destination + str(image_number)+'.JPG'\n",
    "    !fswebcam  --no-banner --save {orig_img_path} -d /dev/video0 2> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face Detection Function\n",
    "def detectFaces(image_name):\n",
    "    #print (\"Face Detection Start.\")\n",
    "    # Read the image and convert to gray to reduce the data\n",
    "    img = cv2.imread(image_name)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)#Color => Gray\n",
    "    \n",
    "    # The haarcascades classifier is used to train data\n",
    "    face_cascade = cv2.CascadeClassifier(\"/usr/share/opencv/haarcascades/haarcascade_frontalface_default.xml\")\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)#1.3 and 5are the min and max windows of the treatures\n",
    "    result = []\n",
    "    for (x,y,width,height) in faces:\n",
    "        result.append((x,y,x+width,y+height))\n",
    "    #print (\"Face Detection Complete.\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(image):\n",
    "    img_ori = Image.open(image)\n",
    "    plt.imshow(img_ori),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crop faces and save them in the same directory\n",
    "def crop():\n",
    "    filepath =\"/home/xilinx/jupyter_notebooks/Final_presents/images/\"\n",
    "    dir_path =\"/home/xilinx/jupyter_notebooks/Final_presents/\"\n",
    "    filecount = len(os.listdir(filepath))-1\n",
    "    image_count = 1#count is the number of images\n",
    "    face_cascade = cv2.CascadeClassifier(\"/usr/share/opencv/haarcascades/haarcascade_frontalface_default.xml\")\n",
    "    for fn in os.listdir(filepath): #fn 表示的是文件名\n",
    "        start = time.time()\n",
    "        if image_count <= filecount:\n",
    "            image_name = str(image_count) + '.JPG'\n",
    "            image_path = filepath + image_name\n",
    "            image_new = dir_path + image_name\n",
    "            #print (image_path)\n",
    "            #print (image_new)\n",
    "            os.system('cp '+(image_path)+ (' /home/xilinx/jupyter_notebooks/Final_presents/'))\n",
    "            faces = detectFaces(image_name)\n",
    "            if not faces:\n",
    "                print (\"There is no face!Trust me!!!\")\n",
    "            if faces:\n",
    "                #All croped face images will be saved in a subdirectory\n",
    "                face_name = image_name.split('.')[0]\n",
    "                #os.mkdir(save_dir)\n",
    "                count = 0\n",
    "                for (x1,y1,x2,y2) in faces:\n",
    "                    file_name = os.path.join(dir_path,face_name+str(count)+\".jpg\")\n",
    "                    face_name = os.path.basename(file_name)\n",
    "                    #print (face_name)\n",
    "                    Image.open(image_name).crop((x1,y1,x2,y2)).save(file_name)\n",
    "                    #os.system('rm -rf '+(image_path)+' /home/xilinx/jupyter_notebooks/OpenCV/Face_Detection/')\n",
    "                    count+=1    \n",
    "                    print(\"Haha, Here is one face:\")\n",
    "                    draw(file_name)\n",
    "                    #hdmi(file_name)\n",
    "                #print(\"The \" + str(image_count) +\" image were done.\")\n",
    "                #print(\"Congratulation! The total of the \" + str(count) + \" faces in the \" +str(image_count) + \" image.\")\n",
    "                \n",
    "    \n",
    "\n",
    "                # Integration START\n",
    "\n",
    "\n",
    "\n",
    "                # New face from the webcam\n",
    "                image = file_name\n",
    "\n",
    "                # Find the Key point\n",
    "                img = cv2.imread(image,0)          # queryImage\n",
    "\n",
    "                # find the keypoints and descriptors with ORB\n",
    "                kp1, des1 = orb.detectAndCompute(img,None)\n",
    "\n",
    "                # Extract and print all of the values\n",
    "                all_faces_str = sheet.get_all_values()\n",
    "\n",
    "\n",
    "                # convert google doc strings to numbers\n",
    "                data = all_faces_str[1:]\n",
    "                face_order = 0\n",
    "                for row in data:\n",
    "\n",
    "                    face_order += 1\n",
    "                    myTotal = np.array([])\n",
    "                    for element in row:\n",
    "                        myArray = np.array(eval(element))\n",
    "                        myTotal = np.vstack([myTotal,myArray]) if myTotal.size else myArray\n",
    "\n",
    "\n",
    "                    # convert data type\n",
    "                    myTotal_uint8 = np.uint8(myTotal) \n",
    "\n",
    "                    # Add each image descriptor list from the database\n",
    "                    clusters = np.array([myTotal_uint8])\n",
    "                    bf.add(clusters)\n",
    "\n",
    "                    # Train: Does nothing for BruteForceMatcher though.\n",
    "                    bf.train()\n",
    "\n",
    "                    matches = bf.match(des1,myTotal_uint8)\n",
    "                    matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "                    facest_face = 0\n",
    "                    numb_matches = (len(matches))\n",
    "                    if numb_matches > facest_face:\n",
    "                        facest_face = numb_matches\n",
    "\n",
    "                    face_found = False\n",
    "                    if facest_face > thres_hold:\n",
    "                        face_found = True\n",
    "                        found_face_order = face_order\n",
    "\n",
    "\n",
    "\n",
    "                # Add face to database if not found, otherwise report the face\n",
    "                if face_found == True:\n",
    "                    print (\"FACE FOUND! Face number:\")\n",
    "                    print (found_face_order)\n",
    "                else:\n",
    "                    print (\"Face NOT found. adding face to database\")\n",
    "                    sheet.append_row('')\n",
    "                    col_in = 1\n",
    "                    row_in = sheet.row_count\n",
    "\n",
    "                    collumn_list = []\n",
    "                    des_cnt = 0\n",
    "                    des_per_cell = 100\n",
    "                    for collumn in des1:\n",
    "\n",
    "                        collumn_list.append(collumn.tolist())\n",
    "                        # Append des_per_cell # of collumns into a single collumn and upload\n",
    "                        if des_cnt >= des_per_cell -1:\n",
    "                            print (\"cloud\")\n",
    "                            sheet.update_cell(row_in, col_in, collumn_list)\n",
    "                            collumn_list = []\n",
    "                            col_in += 1\n",
    "                            des_cnt = 0\n",
    "                        else:\n",
    "                            des_cnt += 1\n",
    "\n",
    "\n",
    "\n",
    "                # Integration END\n",
    "            \n",
    "            \n",
    "           \n",
    "                \n",
    "                os.system('rm -rf '+(image_path))\n",
    "            os.system('rm -rf '+(image_new))\n",
    "        end = time.time()\n",
    "        TimeSpan = end - start\n",
    "        if image_count <= filecount:\n",
    "            print (\"The time of \" + str(image_count) + \" image is \" +str(TimeSpan) + \" s.\")\n",
    "        image_count = image_count + 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hdmi(file_name):\n",
    "    base = BaseOverlay(\"base.bit\")\n",
    "    # monitor configuration: 640*480 @ 60Hz\n",
    "    Mode = VideoMode(640,480,24)\n",
    "    hdmi_out = base.video.hdmi_out\n",
    "    hdmi_out.configure(Mode,PIXEL_BGR)\n",
    "    hdmi_out.start()\n",
    "    \n",
    "    # monitor (output) frame buffer size\n",
    "    frame_out_w = 1920\n",
    "    frame_out_h = 1080\n",
    "    # camera (input) configuration\n",
    "    frame_in_w = 67\n",
    "    frame_in_h = 67\n",
    "    \n",
    "    import cv2\n",
    "\n",
    "    videoIn = cv2.VideoCapture(file_name)\n",
    "    videoIn.set(cv2.CAP_PROP_FRAME_WIDTH, frame_in_w);\n",
    "    videoIn.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_in_h);\n",
    "\n",
    "    print(\"Capture device is open: \" + str(videoIn.isOpened()))\n",
    "    \n",
    "    # Capture webcam image\n",
    "    import numpy as np\n",
    "\n",
    "    ret, frame_vga = videoIn.read()\n",
    "\n",
    "    # Display webcam image via HDMI Out\n",
    "    if (ret):      \n",
    "        outframe = hdmi_out.newframe()\n",
    "        outframe[0:67,0:67,:] = frame_vga[0:67,0:67,:]\n",
    "        hdmi_out.writeframe(outframe)\n",
    "    else:\n",
    "        raise RuntimeError(\"Failed to read from camera.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    while(base.buttons[0].read()==0):\n",
    "        image_number = 1\n",
    "        filepath =\"/home/xilinx/jupyter_notebooks/Final_presents/images/\"\n",
    "        capture(filepath, image_number)\n",
    "        crop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

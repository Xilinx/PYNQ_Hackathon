{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, every face will be cropped and saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xilinx/jupyter_notebooks/Final_present\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell, some libraries were imported\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import pylab\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# use creds to create a client to interact with the Google Drive API\n",
    "scope = ['https://spreadsheets.google.com/feeds']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('client_secret.json', scope)\n",
    "client = gspread.authorize(creds)\n",
    " \n",
    "# Find a workbook by name and open the first sheet\n",
    "# Make sure you use the right name here.\n",
    "sheet = client.open(\"Xilinx_Hackathon_2017\").sheet1\n",
    "\n",
    "\n",
    "###### ORB\n",
    "# imports for ORB\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Initiate ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# create BFMatcher object\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "import string\n",
    "import re\n",
    "####################################\n",
    "######   Configurable items:  ######\n",
    "####################################\n",
    "# arbitary number. Fine tune once you get here\n",
    "thres_hold = 250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face Detection Function\n",
    "def detectFaces(image_name):\n",
    "    print (\"Face Detection Start.\")\n",
    "    # Read the image and convert to gray to reduce the data\n",
    "    img = cv2.imread(image_name)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)#Color => Gray\n",
    "    \n",
    "    # The haarcascades classifier is used to train data\n",
    "    #face_cascade = cv2.CascadeClassifier(\"/usr/share/opencv/haarcascades/haarcascade_frontalface_default.xml\")\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.2, 5)#1.3 and 5are the min and max windows of the treatures\n",
    "    result = []\n",
    "    for (x,y,width,height) in faces:\n",
    "        result.append((x,y,x+width,y+height))\n",
    "    print (\"Face Detection Complete.\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Detection Start.\n",
      "Face Detection Complete.\n",
      "The 1 image were done.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f0c08d344c48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#os.system('rm -rf '+(image_new))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_count\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\" image were done.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Congratulation! The total of the \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" faces in the \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_count\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" image.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mimage_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_count\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count' is not defined"
     ]
    }
   ],
   "source": [
    "#Crop faces and save them in the same directory\n",
    "filepath =\"/home/xilinx/jupyter_notebooks/Final_presents/images/\"\n",
    "dir_path =\"/home/xilinx/jupyter_notebooks/Final_presents/\"\n",
    "filecount = len(os.listdir(filepath))-1\n",
    "image_count = 1#count is the number of images\n",
    "face_cascade = cv2.CascadeClassifier(\"/usr/share/opencv/haarcascades/haarcascade_frontalface_default.xml\")\n",
    "for fn in os.listdir(filepath): #fn 表示的是文件名\n",
    "    start = time.time()\n",
    "    if image_count <= filecount:\n",
    "        image_name = str(image_count) + '.JPG'\n",
    "        image_path = filepath + image_name\n",
    "        image_new = dir_path + image_name\n",
    "        #print (image_path)\n",
    "        #print (image_new)\n",
    "        os.system('cp '+(image_path)+ (' /home/xilinx/jupyter_notebooks/Final_presents/'))\n",
    "        faces = detectFaces(image_name)\n",
    "        if not faces:\n",
    "            print (\"Error to detect face\")\n",
    "        if faces:\n",
    "            #All croped face images will be saved in a subdirectory\n",
    "            face_name = image_name.split('.')[0]\n",
    "            #os.mkdir(save_dir)\n",
    "            count = 0\n",
    "            for (x1,y1,x2,y2) in faces:\n",
    "                file_name = os.path.join(dir_path,face_name+str(count)+\".jpg\")\n",
    "                Image.open(image_name).crop((x1,y1,x2,y2)).save(file_name)\n",
    "                #os.system('rm -rf '+(image_path)+' /home/xilinx/jupyter_notebooks/OpenCV/Face_Detection/')\n",
    "                count+=1 \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # Integration START\n",
    "            \n",
    "            \n",
    "            \n",
    "            # New face from the webcam\n",
    "            image = file_name\n",
    "\n",
    "            # Find the Key point\n",
    "            img = cv2.imread(image,0)          # queryImage\n",
    "\n",
    "            # find the keypoints and descriptors with ORB\n",
    "            kp1, des1 = orb.detectAndCompute(img,None)\n",
    "            \n",
    "            # Extract and print all of the values\n",
    "            all_faces_str = sheet.get_all_values()\n",
    "            \n",
    "            \n",
    "            # convert google doc strings to numbers\n",
    "            data = all_faces_str[1:]\n",
    "            face_order = 0\n",
    "            for row in data:\n",
    "\n",
    "                face_order += 1\n",
    "                myTotal = np.array([])\n",
    "                for element in row:\n",
    "                    myArray = np.array(eval(element))\n",
    "                    myTotal = np.vstack([myTotal,myArray]) if myTotal.size else myArray\n",
    "\n",
    "\n",
    "                # convert data type\n",
    "                myTotal_uint8 = np.uint8(myTotal) \n",
    "\n",
    "                # Add each image descriptor list from the database\n",
    "                clusters = np.array([myTotal_uint8])\n",
    "                bf.add(clusters)\n",
    "\n",
    "                # Train: Does nothing for BruteForceMatcher though.\n",
    "                bf.train()\n",
    "\n",
    "                matches = bf.match(des1,myTotal_uint8)\n",
    "                matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "                facest_face = 0\n",
    "                numb_matches = (len(matches))\n",
    "                if numb_matches > facest_face:\n",
    "                    facest_face = numb_matches\n",
    "\n",
    "                face_found = False\n",
    "                if facest_face > thres_hold:\n",
    "                    face_found = True\n",
    "                    found_face_order = face_order\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Add face to database if not found, otherwise report the face\n",
    "            if face_found == True:\n",
    "                print (\"FACE FOUND! Face number:\")\n",
    "                print (found_face_order)\n",
    "            else:\n",
    "                print (\"Face NOT found. adding face to database\")\n",
    "                sheet.append_row('')\n",
    "                col_in = 1\n",
    "                row_in = sheet.row_count\n",
    "\n",
    "                collumn_list = []\n",
    "                des_cnt = 0\n",
    "                des_per_cell = 100\n",
    "                for collumn in des1:\n",
    "\n",
    "                    collumn_list.append(collumn.tolist())\n",
    "                    # Append des_per_cell # of collumns into a single collumn and upload\n",
    "                    if des_cnt >= des_per_cell -1:\n",
    "                        print (\"cloud\")\n",
    "                        sheet.update_cell(row_in, col_in, collumn_list)\n",
    "                        collumn_list = []\n",
    "                        col_in += 1\n",
    "                        des_cnt = 0\n",
    "                    else:\n",
    "                        des_cnt += 1\n",
    "\n",
    "            \n",
    "            \n",
    "            # Integration END\n",
    "            \n",
    "            \n",
    "            \n",
    "            os.system('rm -rf '+(image_new))\n",
    "            print(\"The \" + str(image_count) +\" image were done.\")\n",
    "            print(\"Congratulation! The total of the \" + str(count) + \" faces in the \" +str(image_count) + \" image.\")\n",
    "    end = time.time()\n",
    "    TimeSpan = end - start\n",
    "    if image_count <= filecount:\n",
    "        print (\"The time of \" + str(image_count) + \" image is \" +str(TimeSpan) + \" s.\")\n",
    "    image_count = image_count + 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "img1 = cv2.imread('20.jpg',cv2.COLOR_BGR2GRAY)\n",
    "img2 = cv2.imread('31.jpg',cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the keypoints and descriptors with SIFT for face 1\n",
    "kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "imgOut1 = cv2.drawKeypoints(img1,kp,None, color=(255,0,0), flags=0)\n",
    "plt.imshow(imgOut1),plt.show()\n",
    "\n",
    "# find the keypoints and descriptors with SIFT for face 2\n",
    "kp2, des2 = orb.detectAndCompute(img2,None)\n",
    "imgOut2 = cv2.drawKeypoints(img2,kp,None, color=(255,0,0), flags=0)\n",
    "plt.imshow(imgOut2),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create BFMatcher object\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "# Match descriptors.\n",
    "matches = bf.match(des1,des2)\n",
    "\n",
    "# Sort them in the order of their distance.\n",
    "matches = sorted(matches, key = lambda x:x.distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawMatches(img1, kp1, img2, kp2, matches):\n",
    "    \"\"\"\n",
    "    My own implementation of cv2.drawMatches as OpenCV 2.4.9\n",
    "    does not have this function available but it's supported in\n",
    "    OpenCV 3.0.0\n",
    "\n",
    "    This function takes in two images with their associated \n",
    "    keypoints, as well as a list of DMatch data structure (matches) \n",
    "    that contains which keypoints matched in which images.\n",
    "\n",
    "    An image will be produced where a montage is shown with\n",
    "    the first image followed by the second image beside it.\n",
    "\n",
    "    Keypoints are delineated with circles, while lines are connected\n",
    "    between matching keypoints.\n",
    "\n",
    "    img1,img2 - Grayscale images\n",
    "    kp1,kp2 - Detected list of keypoints through any of the OpenCV keypoint \n",
    "              detection algorithms\n",
    "    matches - A list of matches of corresponding keypoints through any\n",
    "              OpenCV keypoint matching algorithm\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a new output image that concatenates the two images together\n",
    "    # (a.k.a) a montage\n",
    "    rows1 = img1.shape[0]\n",
    "    cols1 = img1.shape[1]\n",
    "    rows2 = img2.shape[0]\n",
    "    cols2 = img2.shape[1]\n",
    "\n",
    "    out = np.zeros((max([rows1,rows2]),cols1+cols2,3), dtype='uint8')\n",
    "\n",
    "    # Place the first image to the left\n",
    "    out[:rows1,:cols1] = np.dstack([img1, img1, img1])\n",
    "\n",
    "    # Place the next image to the right of it\n",
    "    out[:rows2,cols1:] = np.dstack([img2, img2, img2])\n",
    "\n",
    "    # For each pair of points we have between both images\n",
    "    # draw circles, then connect a line between them\n",
    "    for mat in matches:\n",
    "\n",
    "        # Get the matching keypoints for each of the images\n",
    "        img1_idx = mat.queryIdx\n",
    "        img2_idx = mat.trainIdx\n",
    "\n",
    "        # x - columns\n",
    "        # y - rows\n",
    "        (x1,y1) = kp1[img1_idx].pt\n",
    "        (x2,y2) = kp2[img2_idx].pt\n",
    "\n",
    "        # Draw a small circle at both co-ordinates\n",
    "        # radius 4\n",
    "        # colour blue\n",
    "        # thickness = 1\n",
    "        cv2.circle(out, (int(x1),int(y1)), 4, (255, 0, 0), 1)   \n",
    "        cv2.circle(out, (int(x2)+cols1,int(y2)), 4, (255, 0, 0), 1)\n",
    "\n",
    "        # Draw a line in between the two points\n",
    "        # thickness = 1\n",
    "        # colour blue\n",
    "        cv2.line(out, (int(x1),int(y1)), (int(x2)+cols1,int(y2)), (255, 0, 0), 1)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw first 10 matches.\n",
    "print (len(matches))\n",
    "img3 = drawMatches(img1,kp1,img2,kp2,matches[:10])\n",
    "\n",
    "plt.imshow(img3),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

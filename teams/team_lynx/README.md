# Lynx Face Recognition

#### Lynx Face Recognition was built for the Xilinx 2017 Hackathon.
Using a constant feed from a webcam, the application recognizes when a face is present, and generates a feature set based on the image data. It will identify the face if it has been seen before, or create a new feature set to recognize a face in the future.

This method is expandable to multiple boards. The feature set data is handed to a google drive database, where other boards can pull keypoints generated by other boards, and apply it to faces recognized.

Lynx Face Detection is built on the Xilinx PYNQ platform. All code is contained within a Jupyter notebook, making it easy to visualize.

Team Lynx:
* Sree Sai
* Dan Connors
* Yan Pang
* Kyle McGrath
* Daniel Hawronsky
* Nikhil Korati Prasanna

## Run it on your PYNQ Board

Prerequisites
* Xilinx PYNQ Board
* Webcam
* Internet Access
* Monitor (optional)
* Follow this guide to enable drive networking https://www.twilio.com/blog/2017/02/an-easy-way-to-read-and-write-to-a-google-spreadsheet-in-python.html


Enter the terminal on your board and run the following:
```
sudo apt-get update
sudo apt-get install python-pip
pip3.6 install gspread oauth2client
cd /home/xilinx/
git clone https://github.com/x11kjm/lynx.git
```
Launch your jupyter notebook, enter into the GO directory, and launch the .ipynb file.

## How it Works
#### Face Detection and Cropping 
We use the Haar-cascade Detection in OpenCV method described here:
http://docs.opencv.org/trunk/d7/d8b/tutorial_py_face_detection.html

The algorithm applys Haar features to the feed generated by the webcam. A single value is generated for each feature by subtracting a sum of pixels under white rectangle from the sum of pixels under the black rectangle. This method is computationally light weight, ideal for the PYNQ board.

![Face Filters](http://docs.opencv.org/trunk/haar.png)

This returns an image with bounding boxes around the faces present in the webcam feed.

![Face Bounding Boxes](http://docs.opencv.org/trunk/face.jpg)

The face is cropped given the bounding box information.

#### ORB Feature Detection and Matching
The cropped images are handed to OpenCV ORB (Oriented FAST and Rotated Brief).
A list of keypoints along with their locations are generated on the image.

![Example Keypoints](http://docs.opencv.org/3.0-beta/_images/orb_kp.jpg)

A list of matches are generated by a brute force matcher. Similar images/faces will generate a higher amount of matches, which we use to score if we have seen the same faces before.

![Comparison of Keypoints](/GO/images/comparison.png)

#### Distributed Recognition
The list of keypoints and locations are uploaded to a Google Spreadsheet using the Drive API. Any new face will be uploaded immediately, and downloaded among the boards. 

When a new face is detected, the code will download the descriptor word database from the Google Sheets file. This action allows for multiple PYNQ boards to perform simulatneous face detects at once. The new image is processed into descriptor words which are then compared to the list of previously detected faces' descriptor words. The new desciptor word is brute force matched to each of the previous descriptor words. The highest match is then checked against the match threshhold and if it exceeds the threshold, the new face is reported to be a match with the order of when the face was previously detected. If there is no match, the new descriptor is uploaded to the Google Sheets document and the face is reported as not being found before to the interface.





{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, every face will be cropped and saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell, some libraries were imported\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import pylab\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face Detection Function\n",
    "def detectFaces(image_name):\n",
    "    print (\"Face Detection Start.\")\n",
    "    # Read the image and convert to gray to reduce the data\n",
    "    img = cv2.imread(image_name)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)#Color => Gray\n",
    "    \n",
    "    # The haarcascades classifier is used to train data\n",
    "    #face_cascade = cv2.CascadeClassifier(\"/usr/share/opencv/haarcascades/haarcascade_frontalface_default.xml\")\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.2, 5)#1.3 and 5are the min and max windows of the treatures\n",
    "    result = []\n",
    "    for (x,y,width,height) in faces:\n",
    "        result.append((x,y,x+width,y+height))\n",
    "    print (\"Face Detection Complete.\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Detection Start.\n",
      "Face Detection Complete.\n",
      "The 1 image were done.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2f9190c86c93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm -rf '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_count\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\" image were done.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Congratulation! The total of the \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" faces in the \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_count\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" image.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mimage_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_count\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count' is not defined"
     ]
    }
   ],
   "source": [
    "#Crop faces and save them in the same directory\n",
    "filepath =\"/home/xilinx/jupyter_notebooks/OpenCV/Face_Detection/images/\"\n",
    "dir_path =\"/home/xilinx/jupyter_notebooks/OpenCV/Face_Detection/\"\n",
    "filecount = len(os.listdir(filepath))-1\n",
    "image_count = 1#count is the number of images\n",
    "face_cascade = cv2.CascadeClassifier(\"/usr/share/opencv/haarcascades/haarcascade_frontalface_default.xml\")\n",
    "for fn in os.listdir(filepath): #fn 表示的是文件名\n",
    "    start = time.time()\n",
    "    if image_count <= filecount:\n",
    "        image_name = str(image_count) + '.JPG'\n",
    "        image_path = filepath + image_name\n",
    "        image_new = dir_path + image_name\n",
    "        #print (image_path)\n",
    "        #print (image_new)\n",
    "        os.system('cp '+(image_path)+ (' /home/xilinx/jupyter_notebooks/OpenCV/Face_Detection/'))\n",
    "        faces = detectFaces(image_name)\n",
    "        if not faces:\n",
    "            print (\"Error to detect face\")\n",
    "        if faces:\n",
    "            #All croped face images will be saved in a subdirectory\n",
    "            face_name = image_name.split('.')[0]\n",
    "            #os.mkdir(save_dir)\n",
    "            count = 0\n",
    "            for (x1,y1,x2,y2) in faces:\n",
    "                file_name = os.path.join(dir_path,face_name+str(count)+\".jpg\")\n",
    "                Image.open(image_name).crop((x1,y1,x2,y2)).save(file_name)\n",
    "                #os.system('rm -rf '+(image_path)+' /home/xilinx/jupyter_notebooks/OpenCV/Face_Detection/')\n",
    "                count+=1    \n",
    "            os.system('rm -rf '+(image_new))\n",
    "            print(\"The \" + str(image_count) +\" image were done.\")\n",
    "            print(\"Congratulation! The total of the \" + str(count) + \" faces in the \" +str(image_count) + \" image.\")\n",
    "    end = time.time()\n",
    "    TimeSpan = end - start\n",
    "    if image_count <= filecount:\n",
    "        print (\"The time of \" + str(image_count) + \" image is \" +str(TimeSpan) + \" s.\")\n",
    "    image_count = image_count + 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import pylab\n",
    "\n",
    "# Initiate ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "img1 = cv2.imread('/home/xilinx/jupyter_notebooks/OpenCV/Face_Detection/20.jpg',cv2.COLOR_BGR2GRAY)\n",
    "img2 = cv2.imread('/home/xilinx/jupyter_notebooks/OpenCV/Face_Detection/30.jpg',cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#plt.imshow(img1),plt.show()\n",
    "#plt.imshow(img2),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brisk = cv2.BRISK_create()\n",
    "(kpt1, desc1) = brisk.detectAndCompute(img1, None)  \n",
    "bk_img1 = img1.copy()  \n",
    "out_img1 = img1.copy()  \n",
    "out_img1 = cv2.drawKeypoints(bk_img1, kpt1, out_img1)\n",
    "plt.imshow(out_img1),plt.show()\n",
    "\n",
    "(kpt2, desc2) = brisk.detectAndCompute(img1, None)  \n",
    "bk_img2 = img2.copy()  \n",
    "out_img2 = img2.copy()  \n",
    "out_img2 = cv2.drawKeypoints(bk_img2, kpt2, out_img2)  \n",
    "plt.imshow(out_img2),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征点匹配  \n",
    "matcher = cv2.BFMatcher()  \n",
    "matches = matcher.match(desc1, desc2)  \n",
    "print(matches) \n",
    "\n",
    "matches = sorted(matches, key = lambda x:x.distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawMatches(img1, kp1, img2, kp2, matches):\n",
    "    \"\"\"\n",
    "    My own implementation of cv2.drawMatches as OpenCV 2.4.9\n",
    "    does not have this function available but it's supported in\n",
    "    OpenCV 3.0.0\n",
    "\n",
    "    This function takes in two images with their associated \n",
    "    keypoints, as well as a list of DMatch data structure (matches) \n",
    "    that contains which keypoints matched in which images.\n",
    "\n",
    "    An image will be produced where a montage is shown with\n",
    "    the first image followed by the second image beside it.\n",
    "\n",
    "    Keypoints are delineated with circles, while lines are connected\n",
    "    between matching keypoints.\n",
    "\n",
    "    img1,img2 - Grayscale images\n",
    "    kp1,kp2 - Detected list of keypoints through any of the OpenCV keypoint \n",
    "              detection algorithms\n",
    "    matches - A list of matches of corresponding keypoints through any\n",
    "              OpenCV keypoint matching algorithm\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a new output image that concatenates the two images together\n",
    "    # (a.k.a) a montage\n",
    "    rows1 = img1.shape[0]\n",
    "    cols1 = img1.shape[1]\n",
    "    rows2 = img2.shape[0]\n",
    "    cols2 = img2.shape[1]\n",
    "\n",
    "    out = np.zeros((max([rows1,rows2]),cols1+cols2,3), dtype='uint8')\n",
    "\n",
    "    # Place the first image to the left\n",
    "    out[:rows1,:cols1] = np.dstack([img1, img1, img1])\n",
    "\n",
    "    # Place the next image to the right of it\n",
    "    out[:rows2,cols1:] = np.dstack([img2, img2, img2])\n",
    "\n",
    "    # For each pair of points we have between both images\n",
    "    # draw circles, then connect a line between them\n",
    "    for mat in matches:\n",
    "\n",
    "        # Get the matching keypoints for each of the images\n",
    "        img1_idx = mat.queryIdx\n",
    "        img2_idx = mat.trainIdx\n",
    "\n",
    "        # x - columns\n",
    "        # y - rows\n",
    "        (x1,y1) = kp1[img1_idx].pt\n",
    "        (x2,y2) = kp2[img2_idx].pt\n",
    "\n",
    "        # Draw a small circle at both co-ordinates\n",
    "        # radius 4\n",
    "        # colour blue\n",
    "        # thickness = 1\n",
    "        cv2.circle(out, (int(x1),int(y1)), 4, (255, 0, 0), 1)   \n",
    "        cv2.circle(out, (int(x2)+cols1,int(y2)), 4, (255, 0, 0), 1)\n",
    "\n",
    "        # Draw a line in between the two points\n",
    "        # thickness = 1\n",
    "        # colour blue\n",
    "        cv2.line(out, (int(x1),int(y1)), (int(x2)+cols1,int(y2)), (255, 0, 0), 1)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw first 10 matches.\n",
    "print (len(matches))\n",
    "img3 = drawMatches(img1,kpt1,img2,kpt2,matches[:2])\n",
    "\n",
    "plt.imshow(img3),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import cv2  \n",
    "import numpy as np  \n",
    "\n",
    "#I try to compare two images with k-NearestNeighbor (KNN) Algorithm\n",
    "  \n",
    "#img1 = cv2.imread('/home/xilinx/jupyter_notebooks/OpenCV/Face_Detection/images/1.JPG',cv2.COLOR_BGR2GRAY)\n",
    "#img2 = cv2.imread('/home/xilinx/jupyter_notebooks/OpenCV/Face_Detection/images/3.JPG',cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "img1 = cv2.imread('/home/xilinx/jupyter_notebooks/OpenCV/Face_Detection/images/2.JPG')\n",
    "img2 = cv2.imread('/home/xilinx/jupyter_notebooks/OpenCV/Face_Detection/images/3.JPG')\n",
    "  \n",
    "orb = cv2.ORB_create()  \n",
    "  \n",
    "kp1, des1 = orb.detectAndCompute(img1,None)  \n",
    "kp2, des2 = orb.detectAndCompute(img2,None)  \n",
    "  \n",
    "#提取并计算特征点  \n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING) \n",
    "#knn筛选结果  \n",
    "matches = bf.knnMatch(des1, trainDescriptors = des2, k = 2)  \n",
    "good = [m for (m,n) in matches if m.distance < 0.85*n.distance]  \n",
    "#查看最大匹配点数目  \n",
    "print (len(matches))  \n",
    "print (len(good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SnapBack the Smart Hat\n",
    "\n",
    "Snap back your happy moments.\n",
    "\n",
    "<img src=\"img/githubSnapBackCover.jpg\"/>\n",
    "\n",
    "### Team Members\n",
    "##### **Billy Brickner**\n",
    "##### **Nhan Tran**\n",
    "##### **Huan Wang**\n",
    "##### **Tyler Quast**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How it works\n",
    "\n",
    "Webcam-equipped cap that captures happy moments by recognizing smiling faces and using that recognition to trigger the capture of a short video clip, which is then wirelessly uploaded to the cloud for later viewing.\n",
    "\n",
    "<img src=\"img/SnapBack.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardware Setup\n",
    "\n",
    "Our hardware has been designed to be portable to accomodate for the active lifestyle of our memory makers. To make this possible we made some hardware modifications to accomadate for a chordless device.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Battery Pack\n",
    "\n",
    "For power on the go, a power block was repurposed to connect the board to a 9V power source. In this case the power source is three 9V batteries connected in parralel with electrical tape.\n",
    "\n",
    "\n",
    "<img src=\"img/BatteryPack.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peripherals\n",
    "\n",
    "The peripherals that were used were from left to right:\n",
    "**Arduino Shield** - For powering the periferals\n",
    "**USB Webcam** - For capturing memories\n",
    "**USB Wifi** - A Wifi Adapter for uploading memories to the cloud.\n",
    "**USB Splitter** - A Device for allowing multiple inputs into the board\n",
    "\n",
    "\n",
    "<img src=\"img/Periferals.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arduino Shield\n",
    "\n",
    "The ardunio shield was modified to provide power to the peripherals by soldering the usb splitter power wire to the 5V pin on the board.  \n",
    "\n",
    "<img src ='img/ArduinoShield.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protective Case\n",
    "\n",
    "This protective case hold the components together in a compact and discrete manner while you walk around with the snapback.\n",
    "\n",
    "<img src=\"img/ProtectiveCase.jpg\" />\n",
    "\n",
    "#### Everything is in the case! Completely cordless! You can walk around and snapback will capture your happy moments!\n",
    "\n",
    "<img src=\"img/enclosedBox.jpg\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Website Server Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install all the dependencies\n",
    " - pip install dropbox\n",
    " - pip install flask\n",
    "\n",
    "## 2. cd into the Webserver folder\n",
    "expert the path for flask\n",
    "\n",
    " export FLASK_APP=main.py\n",
    "\n",
    "\n",
    "## 3. Run:\n",
    " - flask run\n",
    "\n",
    "to start the server. Go to localhost:5000 to view the site.\n",
    "\n",
    "<img src=\"img/website_demo.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Vision Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In terminal, run python3.6 smile_detector.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python3.6\n",
    "\n",
    "from pynq.overlays.base import BaseOverlay\n",
    "from pynq.lib.video import *\n",
    "import numpy as np\n",
    "from pynq import Xlnk\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "xlnk = Xlnk()\n",
    "xlnk.xlnk_reset()\n",
    "\n",
    "base = BaseOverlay(\"base.bit\")\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    '/home/xilinx/jupyter_notebooks/base/video/data/'\n",
    "    'haarcascade_frontalface_default.xml')\n",
    "smile_cascade = cv2.CascadeClassifier(\n",
    "    '/home/xilinx/jupyter_notebooks/base/video/data/'\n",
    "    'haarcascade_smile.xml')\n",
    "\n",
    "frame_w = 640 \n",
    "frame_h = 480\n",
    "\n",
    "Mode = VideoMode(frame_w, frame_h, 24) \n",
    "hdmi_out = base.video.hdmi_out\n",
    "hdmi_out.configure(Mode, PIXEL_BGR)\n",
    "hdmi_out.start()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(\"Capture device is open? \" + str(cap.isOpened()))\n",
    "\n",
    "#Global Vars\n",
    "start_recording = False\n",
    "trigger_time = 0 #Hold timestamp of the last detection\n",
    "\n",
    "num_smiles = 0\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'H264')  \n",
    "writer = None\n",
    "# Facial and Smile recognition:\n",
    "\n",
    "\n",
    "try:\n",
    "    started = time.time()\n",
    "    while base.buttons[1].read()==0:\n",
    "            ret, frame_vga = cap.read()\n",
    "            if (ret):\n",
    "                \"\"\"\n",
    "                outframe = hdmi_out.newframe()\n",
    "                outframe[:] = frame_vga\n",
    "                hdmi_out.writeframe(outframe)\n",
    "                \"\"\"\n",
    "                \n",
    "                np_frame = frame_vga\n",
    "                \n",
    "                instant = time.time() # get timestamp of the frame\n",
    "\n",
    "                      \n",
    "                gray = cv2.cvtColor(np_frame, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "\n",
    "                faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "                for (x,y,w,h) in faces:\n",
    "                    cv2.rectangle(np_frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "                    roi_gray = gray[y:y+h, x:x+w]\n",
    "                    roi_color = np_frame[y:y+h, x:x+w]\n",
    "                    \"\"\"\n",
    "                    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "                    for (ex,ey,ew,eh) in eyes:\n",
    "                        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "                    \"\"\"\n",
    "                    smiles = smile_cascade.detectMultiScale(\n",
    "                        roi_gray,\n",
    "                        scaleFactor= 1.7,\n",
    "                        minNeighbors=22,\n",
    "                        minSize=(25, 25),\n",
    "                        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "                    )\n",
    "                    for (sx,sy,sw,sh) in smiles:\n",
    "                        print(\"Found\", len(smiles), \"smile(s).\")\n",
    "                        cv2.rectangle(roi_color, (sx,sy), (sx+sw, sy+sh), (255, 0,0), 1)\n",
    "                        #display number of smile on frame:\n",
    "                        text_font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                        bottomLeftCornerOfText = (0,300)\n",
    "                        fontScale = 1\n",
    "                        fontColor = (255,255,255)\n",
    "                        lineType = 2        \n",
    "                        cv2.putText(np_frame,\"Found {} smile(s)!\".format(len(smiles)), \n",
    "                            bottomLeftCornerOfText, \n",
    "                            text_font, \n",
    "                            fontScale,\n",
    "                            fontColor,\n",
    "                            lineType)\n",
    "                    if len(smiles) > 0:\n",
    "                        if writer is None:\n",
    "                            writer =cv2.VideoWriter('capture_moments/'+time.strftime(\"%Y%m%d-%H%M%S\") + '.mp4',fourcc, 2.5, (frame_w,frame_h))\n",
    "\n",
    "                        num_smiles = len(smiles)\n",
    "                        trigger_time = instant\n",
    "                        start_recording = True\n",
    "                    if start_recording and instant <= trigger_time + 30:\n",
    "                        writer.write(frame_vga)\n",
    "                        print(\"writing because \", instant, trigger_time + 10)\n",
    "                    else:\n",
    "                        print(\"STOP RECORDING\")\n",
    "                        start_recording = False\n",
    "                        if writer is not None:\n",
    "                            writer.release()\n",
    "                            os.system(\"python3.6 dropbox_support.py\")\n",
    "                            writer = None\n",
    "                        \n",
    "                        #capture_video('captured_moments', 5)\n",
    "                        \n",
    "                        # capture smiling images\n",
    "                        #cv2.imwrite('capture_moments/' + time.strftime(\"%Y%m%d-%H%M%S\") + '.jpg', frame_vga)\n",
    "                        \n",
    "\n",
    "                # Output OpenCV results via HDMI\n",
    "                outframe = hdmi_out.newframe()\n",
    "                outframe[0:480,0:640,:] = frame_vga[0:480,0:640,:]\n",
    "\n",
    "                #outframe = hdmi_out.newframe()\n",
    "                #outframe[:] = frame\n",
    "                \n",
    "                hdmi_out.writeframe(outframe)\n",
    "                \n",
    "            else:\n",
    "                raise RuntimeError(\"Error while reading from camera\")\n",
    "finally:\n",
    "    print(\"Cancel\")\n",
    "    hdmi_out.stop()\n",
    "    cap.release()\n",
    "    if writer is not None:\n",
    "        writer.release()\n",
    "        os.system(\"python3.6 dropbox_support.py\")\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

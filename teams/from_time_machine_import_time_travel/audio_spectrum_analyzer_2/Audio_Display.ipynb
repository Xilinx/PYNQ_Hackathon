{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Waveform Display\n",
    "This notebook will sample audio via the microphone, display the time domain waveform, take an FFT and display the frequency domain. It uses the matplotlib library, converts the figure to a numpy and loads it into the HDMI out framebuffer. Connect a monitor to the HDMI OUT connector. Test with a tone generator app on a smartphone.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From pynq import the BaseOverlay, video, & audio\n",
    "\n",
    "from pynq.lib.video import *\n",
    "from pynq.lib.audio import *\n",
    "from pynq.overlays.base import BaseOverlay\n",
    "\n",
    "base = BaseOverlay('base.bit')\n",
    "hdmi_out = base.video.hdmi_out\n",
    "pAudio = base.audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert matplotlib figure to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert matplotlib figures to a numpy array to be loaded to the framebuffer\n",
    "def fig2numpy ( fig ):\n",
    "\n",
    "    # If we haven't already shown or saved the plot, then we need to\n",
    "    # draw the figure first...\n",
    "    fig.canvas.draw ( )\n",
    "\n",
    "    # Now we can save it to a numpy array.\n",
    "    buf = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "    buf = buf.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "    return buf    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the HDMI OUT\n",
    "Setup the HDMI for 1280x720, 24bit (RGB only), no alpha (RGBA 32bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0x355582b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mode = VideoMode(1280,720,24)\n",
    "hdmi_out.configure(Mode)\n",
    "hdmi_out.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the audio signal\n",
    "Sample the microphone, display the time domain, take an FFT and display the freq domain, then send out the HDMI port. Continue looping until PB0 is pressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.fftpack import fft\n",
    "#import time\n",
    "\n",
    "# Setup the figure to match the HDMI resolution\n",
    "fig = plt.figure(figsize=(1280/96, 720/96), dpi=96)\n",
    "\n",
    "# Continue sampling microphone until PB0 is pressed\n",
    "while (base.buttons[0].read()==0):\n",
    "\n",
    "  # Sample microphone\n",
    "  pAudio.record(0.06773)\n",
    "\n",
    "  # The following was taken from the base/audio example\n",
    "  af_uint8 = np.unpackbits(pAudio.buffer.astype(np.int16)\n",
    "                         .byteswap(True).view(np.uint8))\n",
    "  af_dec = signal.decimate(af_uint8,8,zero_phase=True)\n",
    "  af_dec = signal.decimate(af_dec,6,zero_phase=True)\n",
    "  af_dec = signal.decimate(af_dec,2,zero_phase=True)\n",
    "  af_dec = (af_dec[10:-10]-af_dec[10:-10].mean())\n",
    "\n",
    "  del af_uint8\n",
    "\n",
    "  time_axis = np.arange(0,((len(af_dec))/32000),1/32000)\n",
    "  \n",
    "  # Plot the time domain\n",
    "  plt.subplot(211)\n",
    "  plt.cla()\n",
    "  plt.title('Audio Signal in Time & Frequency Domain')\n",
    "  plt.xlabel('Time in s')\n",
    "  plt.ylabel('Amplitude')\n",
    "  plt.ylim((-0.025, 0.025))\n",
    "  # Truncate beginning and end  \n",
    "  plt.plot(time_axis[50:-50], af_dec[50:-50])\n",
    "\n",
    "  # Take the FFT\n",
    "  yf = fft(af_dec[50:-50])\n",
    "  yf_2 = yf[1:len(yf)//2]\n",
    "  xf = np.linspace(0.0, 32000//2, len(yf_2))\n",
    "\n",
    "  # Plot the freq domain\n",
    "  plt.subplot(212)\n",
    "  plt.cla()\n",
    "  plt.semilogx(xf, abs(yf_2))\n",
    "  plt.xlabel('Frequency in Hz')\n",
    "  plt.ylabel('Magnitude')\n",
    "  plt.ylim((0, 15))\n",
    "\n",
    "  # Convert figure to numpy array\n",
    "  buf = fig2numpy (fig)\n",
    "\n",
    "  # Send the image out the framebuffer\n",
    "  outframe = hdmi_out.newframe()\n",
    "  outframe[:] = buf\n",
    "  hdmi_out.writeframe(outframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop the HDMI before quitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_out.stop()\n",
    "del hdmi_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
